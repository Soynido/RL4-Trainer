# RL4-Trainer

**Workspace d'entraÃ®nement autonome pour le Reasoning Layer 4**

Un systÃ¨me headless capable d'entraÃ®ner le RL4 sur des milliers de repositories Git, mesurer ses performances cognitives et gÃ©nÃ©rer automatiquement des meta-ADRs de calibration.

---

## ğŸ¯ Objectif

Le **RL4-Trainer** est conÃ§u pour :

- **Rejouer** l'historique Git de milliers de repositories (simulation temporelle)
- **ExÃ©cuter** les 4 engines cognitifs du RL4 (Pattern, Correlation, Forecast, ADR)
- **Mesurer** les performances via 6 mÃ©triques clÃ©s
- **GÃ©nÃ©rer** automatiquement des feedbacks (meta-ADRs) pour amÃ©liorer le systÃ¨me
- **Optimiser** le Reasoning Layer 4 de maniÃ¨re itÃ©rative et mesurable

---

## ğŸ“ Architecture

```
RL4-Trainer/
â”œâ”€â”€ kernel/                    # Kernel RL4 headless
â”‚   â”œâ”€â”€ RL4KernelTrainer.ts   # Orchestrateur principal
â”‚   â”œâ”€â”€ engines/              # 4 engines cognitifs
â”‚   â”‚   â”œâ”€â”€ PatternLearningEngine.ts
â”‚   â”‚   â”œâ”€â”€ CorrelationEngine.ts
â”‚   â”‚   â”œâ”€â”€ ForecastEngine.ts
â”‚   â”‚   â””â”€â”€ ADRGeneratorV2.ts
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ AppendOnlyWriter.ts
â”‚
â”œâ”€â”€ trainer/                   # Orchestration batch
â”‚   â”œâ”€â”€ trainBatch.ts         # Pipeline complet multi-repos
â”‚   â”œâ”€â”€ replayGitHistory.ts   # Lecteur Git â†’ Ã©vÃ©nements
â”‚   â”œâ”€â”€ workers/              # Workers spÃ©cialisÃ©s
â”‚   â”‚   â””â”€â”€ ASTParserWorker.ts # Analyse syntaxique (AST)
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.ts
â”‚
â”œâ”€â”€ metrics/                   # Calcul et analyse
â”‚   â”œâ”€â”€ MetricsEngine.ts
â”‚   â””â”€â”€ types.ts
â”‚
â”œâ”€â”€ feedback/                  # GÃ©nÃ©ration meta-ADRs
â”‚   â”œâ”€â”€ FeedbackEngine.ts
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ metaADR.ts
â”‚
â”œâ”€â”€ datasets/                  # Repos et donnÃ©es
â”‚   â”œâ”€â”€ repo-list.txt
â”‚   â””â”€â”€ corpus/
â”‚
â””â”€â”€ .reasoning_rl4/           # Output (ledger, mÃ©triques, feedback)
    â”œâ”€â”€ ledger/
    â”œâ”€â”€ metrics/
    â”œâ”€â”€ diagnostics/
    â””â”€â”€ feedback/meta_adrs/
```

---

## ğŸ§© Modules Principaux

### 1. **Kernel Headless** (`kernel/`)

Version sans VS Code du RL4 avec les 4 engines cognitifs :

- **PatternLearningEngine** : DÃ©tecte patterns dans les commits (refactor, bugfix, feature, test, etc.)
- **CorrelationEngine** : Trouve corrÃ©lations entre patterns (temporelles, spatiales, causales, sÃ©mantiques)
- **ForecastEngine** : GÃ©nÃ¨re prÃ©dictions basÃ©es sur corrÃ©lations
- **ADRGeneratorV2** : CrÃ©e des ADRs actionnables Ã  partir des forecasts

**Format du ledger** (JSONL) :
```json
{
  "cycleId": 1,
  "timestamp": "2025-11-03T10:00:00.000Z",
  "phases": {
    "patterns": { "detected": [...], "count": 42 },
    "correlations": { "found": [...], "count": 18 },
    "forecasts": { "predictions": [...], "count": 7 },
    "adrs": { "generated": [...], "count": 3 }
  },
  "merkleRoot": "abc123...",
  "prevMerkleRoot": "def456...",
  "metadata": {
    "repo": "repo-name",
    "duration_ms": 1234,
    "events_processed": 156
  }
}
```

### 2. **Trainer Layer** (`trainer/`)

Orchestration batch et replay Git :

- **replayGitHistory.ts** : Parse l'historique Git et gÃ©nÃ¨re Ã©vÃ©nements normalisÃ©s (JSONL)
- **trainBatch.ts** : Pipeline complet pour traiter N repos en parallÃ¨le avec `p-limit`
- **workers/ASTParserWorker.ts** : Analyse syntaxique (AST) des fichiers TypeScript/JavaScript pour extraire patterns de structure et complexitÃ©

#### ğŸ§  Analyse AST (Nouveau)

Le **ASTParserWorker** enrichit les donnÃ©es d'entraÃ®nement en analysant la structure syntaxique du code :

- **Extraction** : Fonctions, classes, imports, exports, variables
- **ComplexitÃ©** : Calcul automatique basÃ© sur lignes, paramÃ¨tres et branches
- **Contexte** : DÃ©tection tests, dÃ©pendances, exports
- **Output** : `.reasoning_rl4/tmp/ast_*.jsonl`

**Test** : `npm run test:ast`  
**Documentation complÃ¨te** : Voir [AST_ANALYSIS.md](./AST_ANALYSIS.md)

**Format Ã©vÃ©nement Git** :
```typescript
{
  type: "commit",
  timestamp: "2025-11-03T10:15:32Z",
  author: "John Doe <john@example.com>",
  hash: "abc123...",
  message: "fix: resolve authentication bug",
  files: [
    { path: "src/auth.ts", status: "modified", additions: 10, deletions: 5 }
  ],
  metadata: { repo: "my-repo", branch: "main" }
}
```

### 3. **Metrics Engine** (`metrics/`)

Calcule 6 mÃ©triques essentielles :

1. **pattern_density** : `patterns dÃ©tectÃ©s / Ã©vÃ©nements totaux`
2. **correlation_rate** : `corrÃ©lations valides / patterns`
3. **forecast_accuracy** : `forecasts confirmÃ©s / total forecasts`
4. **adr_usefulness** : `ADRs appliquÃ©s / ADRs gÃ©nÃ©rÃ©s`
5. **cycle_time_ms** : DurÃ©e moyenne par cycle
6. **entropy** : DiversitÃ© des patterns (Shannon)

**Output** : `.reasoning_rl4/metrics/stats.json`

### 4. **Feedback Engine** (`feedback/`)

Analyse les mÃ©triques et gÃ©nÃ¨re **meta-ADRs** :

- DÃ©tecte anomalies (seuils configurables)
- GÃ©nÃ¨re recommandations automatiques
- Priorise par impact (critical > high > medium > low)

**Output** : `.reasoning_rl4/feedback/meta_adrs/*.json`

---

## ğŸš€ Installation

```bash
# Cloner le projet
cd RL4-Trainer

# Installer les dÃ©pendances
npm install

# Compiler TypeScript
npm run build
```

**DÃ©pendances** :
- `simple-git` : Lecture historique Git
- `pino` + `pino-pretty` : Logging structurÃ©
- `chalk` : Couleurs console
- `p-limit` : ContrÃ´le concurrence

---

## ğŸ—„ï¸ Pipeline d'Acquisition Dataset

### Ã‰tape 1 : RÃ©cupÃ©rer les Repositories GitHub

Utiliser le script automatisÃ© pour fetcher 1000-5000 repos :

```bash
bash scripts/fetch-repos.sh
```

**RequÃªtes exÃ©cutÃ©es** :
- AI Agents & Reasoning Systems (TypeScript, 50+ stars)
- AI & LLM Frameworks (Python, 100+ stars)
- Developer Tools & VSCode Extensions (TypeScript, 50+ stars)
- Backend & Infrastructure (NestJS, FastAPI, Express, 50+ stars)

**Output** : `datasets/repo-list.txt` (~1000-5000 URLs uniques)

**DurÃ©e estimÃ©e** : 2-5 minutes

### Ã‰tape 2 : Valider le Dataset

```bash
bash scripts/validate-dataset.sh
```

Affiche :
- Nombre total de repos
- Ã‰chantillon des 20 premiers
- Taille disque du corpus
- Warnings si < 500 repos

### Ã‰tape 3 : EntraÃ®nement Progressive (RecommandÃ©)

**âš ï¸ Important** : Pour Ã©viter de saturer la mÃ©moire, utiliser le **Progressive Training Loop** par batches de 200 repos.

#### Option A : Automatique (RecommandÃ©)

```bash
# EntraÃ®nement progressif automatique avec rotation
npm run train-all
```

Ce script :
1. DÃ©coupe le dataset en batches de 200 repos
2. EntraÃ®ne chaque batch (4-5 min/batch)
3. Compacte le ledger â†’ kernel state
4. Archive et purge automatiquement
5. Workspace maintenu **â‰¤ 10 GB constant**

**DurÃ©e estimÃ©e** : 20-25 min pour 1000 repos

#### Option B : Manuel (ContrÃ´le Total)

```bash
# Batch 1 (repos 1-200)
npm run train -- --max-repos 200 --concurrency 8
npm run compact
npm run auto-dump

# Batch 2 (repos 201-400)
npm run train -- --max-repos 200 --concurrency 8
npm run compact
npm run auto-dump

# ... rÃ©pÃ©ter selon besoin

# Fusion finale
npm run merge-kernels
```

**Pipeline automatique** :
1. Lecture de `datasets/repo-list.txt`
2. Clonage avec `git clone --depth 50` (optimisÃ©)
3. Replay Git : extraction des commits
4. EntraÃ®nement RL4 : Pattern â†’ Correlation â†’ Forecast â†’ ADR
5. **Compactage** : Ledger â†’ Kernel State (compression Ã—3000)
6. **Rotation** : Archive + purge (workspace â‰¤ 10 GB)
7. MÃ©triques et feedback

**Avantages** :
- âœ… Workspace constant â‰¤ 10 GB
- âœ… RAM stable 2-4 GB
- âœ… CapacitÃ© illimitÃ©e (batches rotatifs)
- âœ… Kernel state exploitable (5 KB vs 1 GB)

### ParamÃ¨tres RecommandÃ©s

| Cas d'usage | MÃ©thode | DurÃ©e | Stockage Max |
|-------------|---------|-------|--------------|
| Test rapide | `npm run train -- --max-repos 10` | ~30s | 100 MB |
| Validation | `npm run train -- --max-repos 200` | ~4 min | 2 GB |
| Production (1000 repos) | `npm run train-all` (5 batches) | ~20 min | â‰¤ 10 GB |
| Dataset massif (5000 repos) | `npm run train-all` (25 batches) | ~100 min | â‰¤ 10 GB |

**Notes** :
- Le clonage avec `--depth 50` rÃ©duit la taille des repos (facteur 5-10x)
- Le **Progressive Training Loop** maintient le workspace â‰¤ 10 GB constant
- Compression automatique du ledger : ratio Ã—3000
- Kernel state final : 200-500 MB (exploitable pour RL V3)

---

## ğŸ“‹ Workflow d'EntraÃ®nement

### **Phase 1 : PrÃ©paration**

Ajouter les repos Ã  traiter dans `datasets/repo-list.txt` :

```txt
# Repos Ã  analyser
https://github.com/user/repo1
https://github.com/user/repo2
/path/to/local/repo3
```

### **Phase 2 : Replay Git (optionnel)**

```bash
# Rejouer un repo spÃ©cifique
npm run replay -- --repo /path/to/repo --limit 1000

# GÃ©nÃ¨re: datasets/corpus/<repo-name>/commits.jsonl
```

### **Phase 3 : EntraÃ®nement Batch**

```bash
# EntraÃ®ner tous les repos (concurrence: 4)
npm run train

# Avec limite
npm run train -- --max-repos 10 --concurrency 2

# Skip replay si dÃ©jÃ  fait
npm run train -- --skip-replay
```

**Pipeline automatique** :
```
repo-list.txt â†’ replayGitHistory â†’ events.jsonl
                                      â†“
                                 RL4KernelTrainer
                                      â†“
                                 ledger.jsonl
                                      â†“
                                 MetricsEngine
                                      â†“
                                  stats.json
                                      â†“
                                FeedbackEngine
                                      â†“
                              meta_adrs/*.json
```

### **Phase 4 : Analyse**

```bash
# Calculer mÃ©triques + analyse
npm run analyze

# Affiche :
# - MÃ©triques globales et par repo
# - Anomalies dÃ©tectÃ©es
# - Recommandations
```

### **Phase 5 : Feedback**

Les meta-ADRs gÃ©nÃ©rÃ©s dans `.reasoning_rl4/feedback/meta_adrs/` contiennent :

- **Contexte** : mÃ©triques observÃ©es vs seuils
- **Recommandation** : actions concrÃ¨tes Ã  implÃ©menter
- **Impact estimÃ©** : amÃ©lioration attendue

**Exemples de meta-ADRs** :
- "AmÃ©liorer la dÃ©tection de patterns" (density faible)
- "Ã‰largir critÃ¨res de corrÃ©lation" (correlation_rate faible)
- "Calibrer ForecastEngine" (forecast_accuracy faible)
- "Optimiser performances" (cycle_time_ms Ã©levÃ©)

---

## âš™ï¸ Configuration

Ã‰diter `train.config.json` :

```json
{
  "max_repos": 100,
  "concurrency": 4,
  "cycle_interval_ms": 2000,
  "metrics_enabled": true,
  "feedback_enabled": true,
  "output_dir": ".reasoning_rl4",
  "metrics_thresholds": {
    "pattern_density_min": 0.3,
    "correlation_rate_min": 0.5,
    "forecast_accuracy_min": 0.4,
    "cycle_time_max_ms": 3000,
    "entropy_min": 1.5
  }
}
```

---

## ğŸ“Š MÃ©triques et Seuils

| MÃ©trique | Description | Seuil | InterprÃ©tation |
|----------|-------------|-------|----------------|
| **pattern_density** | Ratio patterns/Ã©vÃ©nements | â‰¥ 0.3 | DÃ©tection suffisante |
| **correlation_rate** | Ratio corrÃ©lations/patterns | â‰¥ 0.5 | Liens trouvÃ©s |
| **forecast_accuracy** | PrÃ©cision prÃ©dictions | â‰¥ 0.4 | ModÃ¨le calibrÃ© |
| **adr_usefulness** | UtilitÃ© ADRs gÃ©nÃ©rÃ©s | â‰¥ 0.3 | ADRs pertinents |
| **cycle_time_ms** | Temps par cycle | â‰¤ 3000 | Performances OK |
| **entropy** | DiversitÃ© patterns | â‰¥ 1.5 | Bonne couverture |

---

## ğŸ§  ML Integration (Phase 3) - Tuteurs Cognitifs

### **Vision**

> Le but de cette phase n'est pas d'ajouter du calcul, mais de renforcer la mÃ©moire structurante du RL4.
> Les modÃ¨les ML servent de **tuteurs cognitifs** pour extraire, pondÃ©rer et stabiliser les rÃ©gularitÃ©s que le moteur interne dÃ©tecte dÃ©jÃ .

### **Architecture Hybride**

Le RL4-Trainer intÃ¨gre maintenant 5 bridges ML qui enrichissent les moteurs natifs :

| Bridge | Layer | RÃ´le | Impact |
|--------|-------|------|--------|
| **PAMI** | Analytical | Pattern mining frÃ©quentiel | +150% patterns, coherence 0.2â†’0.5 |
| **Merlion** | Reflective | Raffinement causalitÃ© | Coherence 0.5â†’0.8 |
| **HyperTS** | Forecast | ProbabilitÃ©s ML | Forecast precision 0â†’0.6 |
| **FP-Growth** | Analytical | Optimisation >10k sÃ©quences | RÃ©duction temps Ã—5-10 |
| **SPMF** | Structural | Patterns universels | Universals >100 |

### **Installation Rapide**

```bash
# 1. Installer les modules ML (5-10 min)
npm run bootstrap-ml

# 2. Tester les bridges
npm run test:bridges

# 3. EntraÃ®ner avec ML activÃ©
npm run train:ml
```

**Guide complet** : Voir [ML_INTEGRATION_GUIDE.md](./ML_INTEGRATION_GUIDE.md)

### **Fallback Automatique**

En cas d'erreur ou timeout > 300s :
- âœ… Retour automatique sur mÃ©thodes natives
- âœ… Logging dans `.reasoning_rl4/logs/bridges/`
- âœ… Training continue sans interruption
- âœ… StabilitÃ© garantie sur runs nocturnes

### **MÃ©triques Cibles**

| Phase | Coherence | Forecast Precision | Universals |
|-------|-----------|-------------------|------------|
| Phase 2 | 0.5 | 0.4 | 20 |
| Phase 3 | 0.8 | 0.6 | 50 |
| Phase 4 | >0.9 | >0.75 | >100 |

---

## ğŸ”„ IntÃ©gration avec Reasoning Layer V3

### **Workflow Complet**

1. **Dataset** : AcquÃ©rir repos avec `bash scripts/fetch-repos.sh`
   ```bash
   # RÃ©cupÃ©rer 1000-5000 repos GitHub
   bash scripts/fetch-repos.sh
   
   # Valider le dataset
   bash scripts/validate-dataset.sh
   ```

2. **Baseline** : EntraÃ®ner RL4 version N sur dataset A
   ```bash
   npm run train -- --max-repos 1000
   npm run analyze
   ```

3. **Identifier** : Lire meta-ADRs dans `.reasoning_rl4/feedback/meta_adrs/`
   ```bash
   cat .reasoning_rl4/feedback/meta_adrs/index.json
   ```

4. **ImplÃ©menter** : Appliquer recommandations dans le repo `Reasoning Layer V3`
   - Modifier `PatternLearningEngine.ts`
   - Ajuster seuils dans `CorrelationEngine.ts`
   - Calibrer modÃ¨les dans `ForecastEngine.ts`

5. **Valider** : Re-entraÃ®ner et comparer mÃ©triques
   ```bash
   npm run train -- --max-repos 1000
   npm run analyze
   # Comparer stats.json avec baseline
   ```

6. **GÃ©nÃ©raliser** : Tester sur dataset B (non vu)
   ```bash
   # Ajouter nouveaux repos dans repo-list.txt
   npm run train
   ```

7. **ItÃ©rer** : RÃ©pÃ©ter jusqu'Ã  convergence (mÃ©triques stables < 2% variation)

### **Tracking des amÃ©liorations**

Sauvegarder les rapports de mÃ©triques par version :

```bash
cp .reasoning_rl4/metrics/stats.json metrics-history/v1.0.0.json
# AprÃ¨s modifications
npm run train && npm run analyze
cp .reasoning_rl4/metrics/stats.json metrics-history/v1.1.0.json
# Comparer
diff metrics-history/v1.0.0.json metrics-history/v1.1.0.json
```

---

## ğŸ› ï¸ Commandes CLI

### **Replay Git**
```bash
node dist/trainer/replayGitHistory.js --repo <path> [--limit <n>] [--branch <name>]
```

### **Kernel RL4**
```bash
node dist/kernel/RL4KernelTrainer.js --repo <repo-name> [--events <path>]
```

### **Batch Training**
```bash
node dist/trainer/trainBatch.js [--max-repos <n>] [--concurrency <n>] [--skip-replay]
```

### **Metrics**
```bash
node dist/metrics/MetricsEngine.js [--analyze]
```

### **Feedback**
```bash
node dist/feedback/FeedbackEngine.js [--high-only] [--export-md]
```

### **Dashboard**
```bash
npm run dashboard
```

Affiche les tendances d'Ã©volution entre runs successifs :
- Comparaison patterns/correlations/forecasts/ADRs
- Tendances avec pourcentages d'Ã©volution
- DensitÃ© cognitive et taux de corrÃ©lation
- Export JSON dans `.reasoning_rl4/metrics/dashboard-latest.json`

---

## ğŸ“ˆ Exemple de Sortie

### **Training Summary**
```
============================================================
BATCH TRAINING SUMMARY
============================================================
Total Repos:     5
Successful:      4 âœ“
Failed:          1 âœ—
Total Duration:  127.45s
Start Time:      2025-11-03T10:00:00.000Z
End Time:        2025-11-03T10:02:07.450Z

--- Successful Repos ---
  âœ“ repo-A: 45 patterns, 12 ADRs (23456ms)
  âœ“ repo-B: 78 patterns, 18 ADRs (34567ms)
  âœ“ repo-C: 34 patterns, 8 ADRs (18234ms)
  âœ“ repo-D: 56 patterns, 14 ADRs (28901ms)

--- Failed Repos ---
  âœ— repo-E: Invalid Git repository
============================================================
```

### **Metrics Report**
```
============================================================
METRICS REPORT
============================================================

--- Global Metrics ---
Pattern Density:      0.423
Correlation Rate:     0.687
Forecast Accuracy:    0.541
ADR Usefulness:       0.312
Cycle Time:           2634ms
Entropy:              2.731
---
Total Events:         1250
Total Patterns:       529
Total Correlations:   364
Total Forecasts:      187
Total ADRs:           52
Total Cycles:         4
============================================================
```

### **Meta-ADRs**
```
============================================================
FEEDBACK ENGINE - META-ADRs GENERATED
============================================================
Total Meta-ADRs: 3
  - High/Critical: 1
  - Medium:        2
  - Low:           0

--- Meta-ADRs (by priority) ---

ğŸŸ  [HIGH] AmÃ©liorer la dÃ©tection de patterns
  ID: 550e8400-e29b-41d4-a716-446655440000
  Metric: pattern_density
  Observed: 0.280 (threshold: 0.300)
  Repos: repo-A, repo-C
  Recommendation: Ã‰tendre les heuristiques du PatternLearningEngine...
  Improvement: Augmentation attendue de 7% de la densitÃ©

ğŸŸ¡ [MEDIUM] AmÃ©liorer la corrÃ©lation entre patterns
  ID: 660e8400-e29b-41d4-a716-446655440001
  Metric: correlation_rate
  Observed: 0.450 (threshold: 0.500)
  Repos: global
  Recommendation: Ã‰largir la fenÃªtre temporelle de recherche...
  Improvement: AmÃ©lioration estimÃ©e de 11% du taux de corrÃ©lation
============================================================
```

---

## ğŸ§ª Validation

### **CritÃ¨res de succÃ¨s**

âœ… Structure complÃ¨te gÃ©nÃ©rÃ©e et compilable (`npm run build`)  
âœ… 1 repo analysÃ© et ledger crÃ©Ã© avec format correct  
âœ… Fichier `stats.json` produit avec 6 mÃ©triques  
âœ… Au moins 1 meta-ADR gÃ©nÃ©rÃ©  
âœ… Batch > 10 repos sans crash  

### **Tests manuels**

```bash
# Test 1: Replay seul
npm run replay -- --repo /path/to/test-repo
ls datasets/corpus/test-repo/commits.jsonl

# Test 2: Kernel seul
npm run kernel -- --repo test-repo
cat .reasoning_rl4/ledger/cycles.jsonl

# Test 3: Pipeline complet
echo "/path/to/test-repo" > datasets/repo-list.txt
npm run train
npm run analyze
ls .reasoning_rl4/feedback/meta_adrs/
```

---

## ğŸ”¬ Mesure de Convergence

Pour Ã©valuer l'amÃ©lioration du RL4 :

1. **Baseline** : EntraÃ®ner version N sur dataset A, sauver mÃ©triques
2. **AmÃ©lioration** : Appliquer meta-ADRs, modifier engines
3. **Re-entraÃ®nement** : Version N+1 sur dataset A, comparer
4. **Validation** : Version N+1 sur dataset B (non vu)
5. **Convergence** : RÃ©pÃ©ter jusqu'Ã  plateau (< 2% variation)

**MÃ©triques cibles** :
- Pattern density : +5% minimum
- Correlation rate : +10% minimum
- Forecast accuracy : +8% minimum
- Cycle time : stabilitÃ© (variation < 15%)

---

## ğŸ“ Notes Techniques

### **Format JSONL**
Tous les fichiers de donnÃ©es utilisent le format JSONL (JSON Lines) :
- 1 objet JSON par ligne
- Append-only (thread-safe)
- Facilite streaming et traitement incrÃ©mental

### **Merkle Root**
Chaque cycle calcule un hash SHA-256 pour garantir :
- IntÃ©gritÃ© des donnÃ©es
- ChaÃ®nage des cycles (blockchain-like)
- DÃ©tection de corruption

### **AppendOnlyWriter**
Writer optimisÃ© pour JSONL :
- Buffer interne (10 lignes ou 5s)
- File locking pour concurrence
- Rotation automatique > 100MB

---

## ğŸ› Troubleshooting

### **"Events file not found"**
```bash
# Relancer le replay
npm run replay -- --repo /path/to/repo
```

### **"Not a valid Git repository"**
```bash
# VÃ©rifier le chemin
git -C /path/to/repo status
```

### **Performances lentes**
```bash
# RÃ©duire concurrence
npm run train -- --concurrency 2

# Limiter nombre de repos
npm run train -- --max-repos 5
```

### **MÃ©triques Ã  0**
```bash
# VÃ©rifier que le ledger existe
cat .reasoning_rl4/ledger/cycles.jsonl

# Relancer le kernel
npm run kernel -- --repo <repo-name>
```

---

## ğŸ“š RÃ©fÃ©rences

- **Reasoning Layer V3** : Repo principal du RL4
- **Pattern Learning** : DÃ©tection heuristique de patterns Git
- **Correlation Analysis** : Analyse temporelle et causale
- **Forecast Models** : PrÃ©diction basÃ©e sur historique
- **ADR (Architecture Decision Records)** : RFC-002

---

## ğŸ“„ Licence

MIT

---

## ğŸ‘¥ Contributeurs

Projet dÃ©veloppÃ© dans le cadre de l'entraÃ®nement et l'amÃ©lioration continue du Reasoning Layer 4.

---

**Version** : 1.0.0  
**Date** : 2025-11-03

