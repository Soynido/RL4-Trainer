# Progressive Training Loop - RL4-Trainer

**EntraÃ®nement par batch avec rotation automatique et gestion mÃ©moire optimisÃ©e**

---

## ğŸ¯ Objectif

Maintenir le workspace **â‰¤ 10 Go** permanent tout en entraÃ®nant sur des milliers de repos.

### Principe

- **Batch de 200 repos** : taille optimale pour saturer le pattern space sans exploser la RAM
- **Rotation automatique** : dÃ¨s que workspace > 9.5 Go â†’ compactage + archive + purge
- **Kernel persistant** : seul le substrat cognitif (~1 Go) est conservÃ© entre batches

---

## ğŸ“¦ Structure des Dossiers

| Dossier | RÃ´le | Taille max |
|---------|------|------------|
| `.reasoning_rl4/ledger/` | Cycles actifs (temp) | â‰¤ 2 Go |
| `.reasoning_rl4/kernel/` | MÃ©moire consolidÃ©e | â‰¤ 1 Go |
| `.reasoning_rl4/archives/` | Ledgers compactÃ©s (.gz) | â‰¤ 1 Go |
| `datasets/corpus/` | Repos clonÃ©s (temp) | â‰¤ 5 Go |
| `archives/substrate/` | Substrats par batch | â‰¤ 1 Go |
| **Total** | | **â‰¤ 10 Go** |

---

## ğŸ”„ Workflow Progressive Training

### 1. EntraÃ®nement par Batch (200 repos)

```bash
# Batch automatique avec rotation
npm run train-all
```

Ce script exÃ©cute :

```
Pour chaque batch de 200 repos:
  1. Train sur 200 repos â†’ gÃ©nÃ¨re ledger (~2-4 Go)
  2. Compact â†’ extrait kernel state (~200 MB)
  3. Archive â†’ ledger-dump-YYYYMMDD.jsonl.gz (~500 MB)
  4. Purge â†’ supprime ledger + corpus
  5. Continue â†’ batch suivant
```

### 2. Rotation Automatique

Le systÃ¨me vÃ©rifie **automatiquement** aprÃ¨s chaque batch si workspace > 9.5 Go.

**IntÃ©grÃ© dans `trainBatch.ts`** :
```typescript
await autoDumpIfNeeded(); // Auto-rotation si > 9.5 GB
```

**Commande manuelle** :
```bash
npm run auto-dump
```

### 3. Compactage du Ledger

Extrait seulement les meta-patterns et substrat cognitif :

```bash
npm run compact
```

**GÃ©nÃ¨re** :
- `.reasoning_rl4/kernel/state.json` (~200 MB)
- Contient : meta-patterns, ADRs, statistiques

**Supprime** :
- Cycles bruts complets (patterns, correlations, forecasts dÃ©taillÃ©s)

### 4. Fusion Multi-Batches

AprÃ¨s plusieurs batches, fusionner les substrats :

```bash
npm run merge-kernels
```

**GÃ©nÃ¨re** :
- `.reasoning_rl4/kernel/global_state.json`
- Ã‰tat cognitif consolidÃ© de tous les batches

---

## âš¡ Ã‰conomie d'Espace

| Ã‰tape | Taille ledger | Taille kernel | Workspace total |
|-------|---------------|---------------|-----------------|
| AprÃ¨s batch 1 (200 repos) | 8 Go | 200 Mo | ~8.5 Go |
| **AprÃ¨s compact + purge** | **0 Go** | **200 Mo** | **~0.5 Go** |
| AprÃ¨s batch 2 (200 repos) | 8 Go | 230 Mo | ~8.5 Go |
| **AprÃ¨s compact + purge** | **0 Go** | **230 Mo** | **~0.5 Go** |
| AprÃ¨s 5 batches (1000 repos) | - | 300 Mo | **~0.8 Go** |

**Gain** : 40 Go â†’ 0.8 Go = **compression Ã—50**

---

## ğŸš€ Commandes Disponibles

### EntraÃ®nement

```bash
# Batch unique de 200 repos
npm run train -- --max-repos 200 --concurrency 8

# Progressive training loop (tous les repos par batches)
npm run train-all

# Avec rotation manuelle
npm run train -- --max-repos 200 && npm run compact
```

### Gestion MÃ©moire

```bash
# Auto-dump (rotation si nÃ©cessaire)
npm run auto-dump

# Compacter ledger actuel
npm run compact

# Fusionner tous les kernel states
npm run merge-kernels

# Nettoyer anciens ledgers
npm run clean-ledgers
```

### Monitoring

```bash
# VÃ©rifier la taille workspace
du -sh .

# DÃ©tail par composant
du -sh .reasoning_rl4/{ledger,kernel,archives} datasets/corpus

# Check progression batch en cours
bash scripts/check-progress.sh
```

---

## ğŸ“Š Exemple de Session ComplÃ¨te

### Session 1 : Premier Batch (repos 1-200)

```bash
# 1. EntraÃ®ner
npm run train -- --max-repos 200 --concurrency 8
# â†’ GÃ©nÃ¨re ~8 Go de ledger

# 2. Compacter
npm run compact
# â†’ Kernel state: 200 MB
# â†’ Ledger rÃ©duit

# 3. Archiver et purger
bash scripts/rotate-ledger.sh
# â†’ Archive: ledger-dump-20251103.jsonl.gz (500 MB)
# â†’ Workspace: ~0.5 Go
```

### Session 2 : DeuxiÃ¨me Batch (repos 201-400)

```bash
# MÃªme workflow
npm run train -- --max-repos 200 --concurrency 8
npm run compact
bash scripts/rotate-ledger.sh
# â†’ Workspace reste â‰¤ 1 Go
```

### Session N : Fusion Finale

```bash
# AprÃ¨s 5 batches (1000 repos)
npm run merge-kernels
# â†’ global_state.json : Ã©tat cognitif complet (~300 MB)
```

---

## ğŸ§  Substrat Cognitif

Le **kernel state** contient :

```json
{
  "version": "1.0.0",
  "generatedAt": "2025-11-03T23:30:00.000Z",
  "batches": 1,
  "totalRepos": 200,
  "totalCycles": 200,
  "consolidated": {
    "patterns": [
      {
        "type": "refactor",
        "confidence": 0.85,
        "frequency": 1250,
        "repos": ["repo1", "repo2", ...]
      }
    ],
    "metaADRs": [
      {
        "id": "...",
        "priority": "high",
        "recommendation": "...",
        "impact": "..."
      }
    ]
  },
  "statistics": {
    "totalPatterns": 15000,
    "totalCorrelations": 172000,
    "totalForecasts": 200,
    "totalADRs": 49,
    "avgPatternsPerRepo": 75,
    "avgCorrelationsPerPattern": 11.5
  },
  "merkleRoot": "abc123..."
}
```

**Avantages** :
- âœ… Compact : 200 MB vs 8 Go de ledger brut
- âœ… Exploitable : patterns consolidÃ©s, ADRs priorisÃ©s
- âœ… Fusionnable : merge possible entre batches
- âœ… Versionnable : Git-friendly (petit fichier JSON)

---

## ğŸ“ˆ StratÃ©gie Multi-Batches (1000+ Repos)

### Approche RecommandÃ©e

```bash
# Batch 1 : 200 repos
npm run train -- --max-repos 200 --concurrency 8
npm run compact

# Batch 2 : 200 repos suivants
npm run train -- --max-repos 200 --concurrency 8
npm run compact

# ... rÃ©pÃ©ter jusqu'Ã  N batches

# Fusion finale
npm run merge-kernels
```

### Approche AutomatisÃ©e

```bash
# Lance tous les batches automatiquement
npm run train-all
```

Le script `trainAll.sh` :
- DÃ©coupe `repo-list.txt` en tranches de 200
- EntraÃ®ne chaque tranche
- Compacte et archive automatiquement
- Purge entre chaque batch
- Produit N kernel states dans `archives/substrate/`

---

## ğŸ”§ Configuration AvancÃ©e

### Ajuster le Seuil de Rotation

Ã‰diter `trainer/autoDumpManager.ts` :

```typescript
const MAX_GB = 9.5; // Modifier selon votre RAM disponible
```

### Ajuster la Taille de Batch

Ã‰diter `scripts/trainAll.sh` :

```bash
BATCH_SIZE=200  # 200 recommandÃ©, max 300
```

### Augmenter la Heap Node (si besoin)

Pour les batches > 200 repos :

```bash
export NODE_OPTIONS="--max-old-space-size=16384"
npm run train -- --max-repos 300
```

---

## ğŸ“Š Monitoring & Diagnostics

### VÃ©rifier l'Ã‰tat Actuel

```bash
# Taille workspace
du -sh .

# DÃ©tail composants
du -sh .reasoning_rl4/{ledger,kernel,archives} datasets/corpus

# Kernel state actuel
cat .reasoning_rl4/kernel/state.json | jq '{repos: .totalRepos, patterns: .consolidated.patterns | length, adrs: .consolidated.metaADRs | length}'

# Archives disponibles
ls -lh .reasoning_rl4/archives/
```

### Logs de Rotation

Les rotations sont loggÃ©es automatiquement dans les logs du training :

```bash
tail -f trainer/logs/training.log | grep -E "(Checking workspace|Workspace rotated)"
```

---

## ğŸ¯ CritÃ¨res de SuccÃ¨s

âœ… **Workspace â‰¤ 10 Go** : Toujours  
âœ… **Batch size** : 200 repos optimal  
âœ… **Kernel state** : â‰¤ 300 MB final  
âœ… **Archives** : Compression â‰¥ 10:1  
âœ… **Pas de perte** : Substrat cognitif prÃ©servÃ©  

---

## ğŸ”„ IntÃ©gration avec Reasoning Layer V3

### Workflow Complet

```bash
# 1. EntraÃ®ner par batches (RL4-Trainer)
cd RL4-Trainer
npm run train-all  # 1000 repos en 5 batches

# 2. Fusionner les substrats
npm run merge-kernels  # â†’ global_state.json

# 3. Extraire les meta-ADRs
node dist/feedback/FeedbackEngine.js

# 4. Appliquer dans RL V3
cd ../Reasoning-Layer-V3
# ImplÃ©menter les recommandations du global_state.json

# 5. Valider
cd ../RL4-Trainer
npm run train -- --max-repos 50  # Test rapide
```

---

## ğŸ’¡ Best Practices

### âœ… Ã€ FAIRE

- Toujours utiliser batches de 200 repos max
- Laisser autoDumpManager gÃ©rer la rotation
- Archiver les kernel states importants
- Fusionner les substrats rÃ©guliÃ¨rement

### âŒ Ã€ Ã‰VITER

- Ne jamais lancer > 300 repos sans rotation
- Ne jamais accumuler > 10 Go sans purge
- Ne jamais supprimer `.reasoning_rl4/kernel/` (mÃ©moire persistante)
- Ne jamais relancer un batch sans avoir compactÃ© le prÃ©cÃ©dent

---

## ğŸš¨ Troubleshooting

### "Out of Memory" ou Node crash

```bash
# Solution 1: RÃ©duire concurrency
npm run train -- --max-repos 200 --concurrency 4

# Solution 2: Augmenter heap
export NODE_OPTIONS="--max-old-space-size=8192"
npm run train -- --max-repos 200
```

### Workspace > 15 Go

```bash
# Rotation manuelle immÃ©diate
bash scripts/rotate-ledger.sh

# Ou clean complet
npm run clean
rm -rf .reasoning_rl4/ledger/*
rm -rf datasets/corpus/*
```

### Kernel state corrompu

```bash
# Reconstruire depuis archive
gunzip -c .reasoning_rl4/archives/ledger-dump-YYYYMMDD.jsonl.gz > temp-ledger.jsonl
# Puis recompact
npm run compact
```

---

## ğŸ“„ Fichiers CrÃ©Ã©s

- `scripts/trainAll.sh` : Boucle progressive automatique
- `scripts/rotate-ledger.sh` : Rotation manuelle  
- `scripts/compact-ledger.ts` : Digestion ledger â†’ kernel
- `scripts/merge-kernel-states.ts` : Fusion multi-batches
- `trainer/autoDumpManager.ts` : Rotation automatique intÃ©grÃ©e

---

**Le RL4-Trainer est maintenant optimisÃ© pour entraÃ®ner sur datasets massifs avec contraintes mÃ©moire strictes** ğŸš€

